{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0830d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Step 1: Import libraries and load API key from .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Ensure your key is loaded\n",
    "assert OPENAI_API_KEY is not None, \"OPENAI_API_KEY not found in .env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6a0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 79 pages\n"
     ]
    }
   ],
   "source": [
    "# üìò Step 2: Load PDF document\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# Replace with your file name (ensure it's in the same folder)\n",
    "loader = PyMuPDFLoader(\"cricketRules.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443c23cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document split into 527 chunks\n",
      "üîç First chunk preview:\n",
      " Laws of Cricket 2017 Code (3rd Edition - 2022) \n",
      "1 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE LAWS OF CRICKET 2017 CODE (3rd Edition - 2022) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "¬© Marylebone Cricket Club\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter that splits based on characters and overlaps slightly\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # Max characters per chunk\n",
    "    chunk_overlap=50     # Overlap to preserve context\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "# Print number of chunks and preview first one\n",
    "print(f\"‚úÖ Document split into {len(chunks)} chunks\")\n",
    "print(\"üîç First chunk preview:\\n\", chunks[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b2d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document split into 527 chunks\n",
      "üîç First chunk preview:\n",
      " Laws of Cricket 2017 Code (3rd Edition - 2022) \n",
      "1 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "THE LAWS OF CRICKET 2017 CODE (3rd Edition - 2022) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "¬© Marylebone Cricket Club\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter that splits based on characters and overlaps slightly\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # Max characters per chunk\n",
    "    chunk_overlap=50     # Overlap to preserve context\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "# Print number of chunks and preview first one\n",
    "print(f\"‚úÖ Document split into {len(chunks)} chunks\")\n",
    "print(\"üîç First chunk preview:\\n\", chunks[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08b9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisse\\AppData\\Local\\Temp\\ipykernel_22640\\3029253719.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\nisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "‚úÖ FAISS vector store created and saved using HuggingFaceEmbeddings.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Use free local embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ‚úÖ Recreate the vector store from chunks\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# ‚úÖ Save it locally\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "print(\"‚úÖ FAISS vector store created and saved using HuggingFaceEmbeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca054004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Answer from PDF:\n",
      "\n",
      "If the side batting last wins the match without losing all its wickets, the result shall be stated as a win by the number of wickets still then to fall.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert api_key is not None, \"OPENAI_API_KEY not found in .env\"\n",
    "\n",
    "# Initialize client (v1+ syntax)\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# Your FAISS search step\n",
    "question = \"How do we say that we win the game?\"\n",
    "docs = vectorstore.similarity_search(question, k=3)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Chat call (new OpenAI API format)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that answers questions based only on the provided context. Do not use any outside information.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print response\n",
    "print(\"üìÑ Answer from PDF:\\n\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
